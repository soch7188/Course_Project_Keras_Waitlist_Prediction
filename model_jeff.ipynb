{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yao-chiehhu/anaconda3/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "import time\n",
    "import pickle\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.pickle', 'rb') as handle:\n",
    "    fullHeadTailDataList = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare two datasets: Enrol+Quota+Wait and Wait-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullHeadTailDataListEQW = []\n",
    "for item in fullHeadTailDataList:\n",
    "    fullHeadTailDataListEQW.append([item['enrol'],item['quota'],item['wait']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullHeadTailDataListWAIT = []\n",
    "for item in fullHeadTailDataList:\n",
    "    fullHeadTailDataListWAIT.append(item['wait'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictableData(_datetime):\n",
    "    index = -1\n",
    "    # Capture datetime\n",
    "    for ind,row in enumerate(fullHeadTailDataList):\n",
    "        if (row['datetime'] == _datetime):\n",
    "            index = ind\n",
    "            \n",
    "    print(\"Index of Predictable Data:\", index)\n",
    "    \n",
    "    \n",
    "    # Found corresponding datetime\n",
    "    if (index != -1):\n",
    "        res = np.asarray(fullHeadTailDataListEQW[index-1:index+1])\n",
    "        print(\"Predictable Data:\", res)\n",
    "        return np.swapaxes(res,0,1).reshape(1,3,2)\n",
    "    else:\n",
    "        return np.zeros(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create lookback "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back=1): \n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset)-look_back):\n",
    "        a = dataset[i:i+look_back]\n",
    "        X.append(a)\n",
    "        Y.append(dataset[i + look_back]) \n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel(model, modelFilenamePrefix):\n",
    "    structureFilename = modelFilenamePrefix + \".json\" \n",
    "    model_json = model.to_json()\n",
    "    with open(structureFilename, \"w\") as f:\n",
    "        f.write(model_json)\n",
    "        \n",
    "    weightFilename = modelFilenamePrefix + \".h5\" \n",
    "    model.save_weights(weightFilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readModel(modelFilenamePrefix):\n",
    "    structureFilename = modelFilenamePrefix + \".json\" \n",
    "    with open(structureFilename, \"r\") as f:\n",
    "        model_json = f.read()\n",
    "    model = model_from_json(model_json)\n",
    "\n",
    "    weightFilename = modelFilenamePrefix + \".h5\" \n",
    "    model.load_weights(weightFilename)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,dataY = create_dataset(fullHeadTailDataListWAIT, 2)\n",
    "dataX,_ = create_dataset(fullHeadTailDataListEQW, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(990, 2, 3)\n",
      "(990,)\n"
     ]
    }
   ],
   "source": [
    "print(dataX.shape)\n",
    "print(dataY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train1(X,Y,_dim):\n",
    "    X = np.asarray(X)\n",
    "    Y = np.asarray(Y)\n",
    "    \n",
    "    print(X[0])\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=_dim, activation='relu')) \n",
    "    model.add(Dense(1, activation='relu'))\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"mae\"])\n",
    "    model.fit(X, Y, epochs=50, batch_size=4, validation_split=0.2)\n",
    "\n",
    "    scores = model.evaluate(X, Y)\n",
    "    print(\"{}: {}\".format(model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 48. 125.   0.  48. 125.   0.]\n",
      "Train on 792 samples, validate on 198 samples\n",
      "Epoch 1/50\n",
      "792/792 [==============================] - 1s 1ms/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 2/50\n",
      "792/792 [==============================] - 0s 346us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 3/50\n",
      "792/792 [==============================] - 0s 334us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 4/50\n",
      "792/792 [==============================] - 0s 365us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 5/50\n",
      "792/792 [==============================] - 0s 357us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 6/50\n",
      "792/792 [==============================] - 0s 341us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 7/50\n",
      "792/792 [==============================] - 0s 331us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 8/50\n",
      "792/792 [==============================] - 0s 343us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 9/50\n",
      "792/792 [==============================] - 0s 368us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 10/50\n",
      "792/792 [==============================] - 0s 378us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 11/50\n",
      "792/792 [==============================] - 0s 361us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 12/50\n",
      "792/792 [==============================] - 0s 349us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 13/50\n",
      "792/792 [==============================] - 0s 343us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 14/50\n",
      "792/792 [==============================] - 0s 317us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 15/50\n",
      "792/792 [==============================] - 0s 323us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 16/50\n",
      "792/792 [==============================] - 0s 338us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 17/50\n",
      "792/792 [==============================] - 0s 364us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 18/50\n",
      "792/792 [==============================] - 0s 340us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 19/50\n",
      "792/792 [==============================] - 0s 330us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 20/50\n",
      "792/792 [==============================] - 0s 361us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 21/50\n",
      "792/792 [==============================] - 0s 359us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 22/50\n",
      "792/792 [==============================] - 0s 357us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 23/50\n",
      "792/792 [==============================] - 0s 368us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 24/50\n",
      "792/792 [==============================] - 0s 360us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 25/50\n",
      "792/792 [==============================] - 0s 367us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 26/50\n",
      "792/792 [==============================] - 0s 366us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 27/50\n",
      "792/792 [==============================] - 0s 348us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 28/50\n",
      "792/792 [==============================] - 0s 340us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 29/50\n",
      "792/792 [==============================] - 0s 341us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 30/50\n",
      "792/792 [==============================] - 0s 340us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 31/50\n",
      "792/792 [==============================] - 0s 380us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 32/50\n",
      "792/792 [==============================] - 0s 351us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 33/50\n",
      "792/792 [==============================] - 0s 363us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 34/50\n",
      "792/792 [==============================] - 0s 337us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 35/50\n",
      "792/792 [==============================] - 0s 325us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 36/50\n",
      "792/792 [==============================] - 0s 327us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 37/50\n",
      "792/792 [==============================] - 0s 349us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 38/50\n",
      "792/792 [==============================] - 0s 357us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 39/50\n",
      "792/792 [==============================] - 0s 333us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 40/50\n",
      "792/792 [==============================] - 0s 350us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 41/50\n",
      "792/792 [==============================] - 0s 365us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 42/50\n",
      "792/792 [==============================] - 0s 364us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 43/50\n",
      "792/792 [==============================] - 0s 379us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 44/50\n",
      "792/792 [==============================] - 0s 357us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 45/50\n",
      "792/792 [==============================] - 0s 348us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 46/50\n",
      "792/792 [==============================] - 0s 328us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "792/792 [==============================] - 0s 340us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 48/50\n",
      "792/792 [==============================] - 0s 352us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 49/50\n",
      "792/792 [==============================] - 0s 337us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "Epoch 50/50\n",
      "792/792 [==============================] - 0s 327us/step - loss: -751.2849 - mean_absolute_error: 47.1452 - val_loss: -354.1947 - val_mean_absolute_error: 22.2172\n",
      "990/990 [==============================] - 0s 18us/step\n",
      "mean_absolute_error: 4215.95959518895\n"
     ]
    }
   ],
   "source": [
    "model1 = train1(dataX.reshape(len(dataX),6), dataY, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainLSTM(X,Y, timestep=1, dim=1):\n",
    "    # Reshape to fit the LSTM model\n",
    "    X = np.swapaxes(X,1,2)\n",
    "        \n",
    "    # Model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(4, input_shape=(timestep,dim)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"mae\"])\n",
    "    model.fit(X, Y, epochs=50, batch_size=8, validation_split=0.2)\n",
    "\n",
    "    # Ealuation\n",
    "    scores = model.evaluate(X, Y)\n",
    "    print(\"{}: {}\".format(model.metrics_names[1], scores[1]*100))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 48.  48.]\n",
      "  [125. 125.]\n",
      "  [  0.   0.]]\n",
      "\n",
      " [[ 48.  60.]\n",
      "  [125. 125.]\n",
      "  [  0.   0.]]\n",
      "\n",
      " [[ 60.  59.]\n",
      "  [125. 125.]\n",
      "  [  0.   0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[138. 138.]\n",
      "  [140. 140.]\n",
      "  [ 17.  17.]]\n",
      "\n",
      " [[138. 138.]\n",
      "  [140. 140.]\n",
      "  [ 17.  17.]]\n",
      "\n",
      " [[138. 138.]\n",
      "  [140. 140.]\n",
      "  [ 17.  17.]]]\n",
      "Train on 792 samples, validate on 198 samples\n",
      "Epoch 1/50\n",
      "792/792 [==============================] - 2s 2ms/step - loss: 45.0454 - mean_absolute_error: 47.8026 - val_loss: 13.0264 - val_mean_absolute_error: 22.8543\n",
      "Epoch 2/50\n",
      "792/792 [==============================] - 0s 583us/step - loss: 9.0393 - mean_absolute_error: 47.6555 - val_loss: -2.5552 - val_mean_absolute_error: 22.6874\n",
      "Epoch 3/50\n",
      "792/792 [==============================] - 0s 530us/step - loss: -106.2707 - mean_absolute_error: 47.4438 - val_loss: -102.9841 - val_mean_absolute_error: 22.2542\n",
      "Epoch 4/50\n",
      "792/792 [==============================] - 0s 544us/step - loss: -570.0164 - mean_absolute_error: 47.0513 - val_loss: -353.1739 - val_mean_absolute_error: 22.1129\n",
      "Epoch 5/50\n",
      "792/792 [==============================] - 0s 569us/step - loss: -582.9184 - mean_absolute_error: 46.9681 - val_loss: -354.1947 - val_mean_absolute_error: 22.0395\n",
      "Epoch 6/50\n",
      "792/792 [==============================] - 0s 559us/step - loss: -582.4014 - mean_absolute_error: 46.8944 - val_loss: -354.1947 - val_mean_absolute_error: 21.7904\n",
      "Epoch 7/50\n",
      "792/792 [==============================] - 0s 555us/step - loss: -720.7617 - mean_absolute_error: 46.2631 - val_loss: -354.1947 - val_mean_absolute_error: 21.3185\n",
      "Epoch 8/50\n",
      "792/792 [==============================] - 0s 559us/step - loss: -732.9765 - mean_absolute_error: 45.9255 - val_loss: -354.1947 - val_mean_absolute_error: 21.1865\n",
      "Epoch 9/50\n",
      "792/792 [==============================] - 0s 529us/step - loss: -730.7847 - mean_absolute_error: 45.9202 - val_loss: -354.1947 - val_mean_absolute_error: 21.1796\n",
      "Epoch 10/50\n",
      "792/792 [==============================] - 0s 574us/step - loss: -740.2165 - mean_absolute_error: 45.8483 - val_loss: -354.1947 - val_mean_absolute_error: 21.1752\n",
      "Epoch 11/50\n",
      "792/792 [==============================] - 0s 548us/step - loss: -739.8730 - mean_absolute_error: 45.8467 - val_loss: -354.1947 - val_mean_absolute_error: 21.1640\n",
      "Epoch 12/50\n",
      "792/792 [==============================] - 0s 513us/step - loss: -739.9227 - mean_absolute_error: 45.8549 - val_loss: -354.1947 - val_mean_absolute_error: 21.1570\n",
      "Epoch 13/50\n",
      "792/792 [==============================] - 0s 542us/step - loss: -736.8137 - mean_absolute_error: 45.8371 - val_loss: -354.1947 - val_mean_absolute_error: 21.1489\n",
      "Epoch 14/50\n",
      "792/792 [==============================] - 0s 567us/step - loss: -741.4697 - mean_absolute_error: 45.8097 - val_loss: -354.1947 - val_mean_absolute_error: 21.1464\n",
      "Epoch 15/50\n",
      "792/792 [==============================] - 0s 580us/step - loss: -742.3129 - mean_absolute_error: 45.8501 - val_loss: -354.1947 - val_mean_absolute_error: 21.1400\n",
      "Epoch 16/50\n",
      "792/792 [==============================] - 0s 564us/step - loss: -737.0302 - mean_absolute_error: 45.7950 - val_loss: -354.1947 - val_mean_absolute_error: 21.0387\n",
      "Epoch 17/50\n",
      "792/792 [==============================] - 0s 567us/step - loss: -728.3788 - mean_absolute_error: 45.7861 - val_loss: -354.1947 - val_mean_absolute_error: 21.0214\n",
      "Epoch 18/50\n",
      "792/792 [==============================] - 0s 514us/step - loss: -739.6430 - mean_absolute_error: 45.7754 - val_loss: -354.1947 - val_mean_absolute_error: 21.0132\n",
      "Epoch 19/50\n",
      "792/792 [==============================] - 0s 534us/step - loss: -730.8789 - mean_absolute_error: 45.7417 - val_loss: -354.1947 - val_mean_absolute_error: 20.9959\n",
      "Epoch 20/50\n",
      "792/792 [==============================] - 0s 526us/step - loss: -736.7904 - mean_absolute_error: 45.7497 - val_loss: -354.1947 - val_mean_absolute_error: 20.9801\n",
      "Epoch 21/50\n",
      "792/792 [==============================] - 0s 552us/step - loss: -737.3511 - mean_absolute_error: 45.7393 - val_loss: -354.1947 - val_mean_absolute_error: 20.9649\n",
      "Epoch 22/50\n",
      "792/792 [==============================] - 0s 566us/step - loss: -732.8957 - mean_absolute_error: 45.6784 - val_loss: -354.1947 - val_mean_absolute_error: 20.9456\n",
      "Epoch 23/50\n",
      "792/792 [==============================] - 0s 553us/step - loss: -738.4860 - mean_absolute_error: 45.6758 - val_loss: -354.1947 - val_mean_absolute_error: 20.9263\n",
      "Epoch 24/50\n",
      "792/792 [==============================] - 0s 534us/step - loss: -739.8719 - mean_absolute_error: 45.6776 - val_loss: -354.1947 - val_mean_absolute_error: 20.9049\n",
      "Epoch 25/50\n",
      "792/792 [==============================] - 0s 524us/step - loss: -739.6702 - mean_absolute_error: 45.6710 - val_loss: -354.1947 - val_mean_absolute_error: 20.8850\n",
      "Epoch 26/50\n",
      "792/792 [==============================] - 0s 538us/step - loss: -743.6269 - mean_absolute_error: 45.6098 - val_loss: -354.1947 - val_mean_absolute_error: 20.8779\n",
      "Epoch 27/50\n",
      "792/792 [==============================] - 0s 541us/step - loss: -742.6550 - mean_absolute_error: 45.5901 - val_loss: -354.1947 - val_mean_absolute_error: 20.8699\n",
      "Epoch 28/50\n",
      "792/792 [==============================] - 0s 548us/step - loss: -743.4354 - mean_absolute_error: 45.6159 - val_loss: -354.1947 - val_mean_absolute_error: 20.8600\n",
      "Epoch 29/50\n",
      "792/792 [==============================] - 0s 590us/step - loss: -744.0417 - mean_absolute_error: 45.6003 - val_loss: -354.1947 - val_mean_absolute_error: 20.8484\n",
      "Epoch 30/50\n",
      "792/792 [==============================] - 0s 551us/step - loss: -735.5896 - mean_absolute_error: 45.5999 - val_loss: -354.1947 - val_mean_absolute_error: 20.8302\n",
      "Epoch 31/50\n",
      "792/792 [==============================] - 0s 577us/step - loss: -741.9917 - mean_absolute_error: 45.6240 - val_loss: -354.1947 - val_mean_absolute_error: 20.8140\n",
      "Epoch 32/50\n",
      "792/792 [==============================] - 0s 573us/step - loss: -744.1265 - mean_absolute_error: 45.5602 - val_loss: -354.1947 - val_mean_absolute_error: 20.8073\n",
      "Epoch 33/50\n",
      "792/792 [==============================] - 0s 568us/step - loss: -739.1581 - mean_absolute_error: 45.5950 - val_loss: -354.1947 - val_mean_absolute_error: 20.7903\n",
      "Epoch 34/50\n",
      "792/792 [==============================] - 0s 578us/step - loss: -736.2589 - mean_absolute_error: 45.5494 - val_loss: -354.1947 - val_mean_absolute_error: 20.7685\n",
      "Epoch 35/50\n",
      "792/792 [==============================] - 0s 584us/step - loss: -742.0950 - mean_absolute_error: 45.5213 - val_loss: -354.1947 - val_mean_absolute_error: 20.7488\n",
      "Epoch 36/50\n",
      "792/792 [==============================] - 0s 576us/step - loss: -736.8809 - mean_absolute_error: 45.4876 - val_loss: -354.1947 - val_mean_absolute_error: 20.6944\n",
      "Epoch 37/50\n",
      "792/792 [==============================] - 0s 541us/step - loss: -742.2059 - mean_absolute_error: 45.4404 - val_loss: -354.1947 - val_mean_absolute_error: 20.6642\n",
      "Epoch 38/50\n",
      "792/792 [==============================] - 0s 569us/step - loss: -742.3352 - mean_absolute_error: 45.3893 - val_loss: -354.1947 - val_mean_absolute_error: 20.5950\n",
      "Epoch 39/50\n",
      "792/792 [==============================] - 0s 543us/step - loss: -746.6423 - mean_absolute_error: 45.3246 - val_loss: -354.1947 - val_mean_absolute_error: 20.5772\n",
      "Epoch 40/50\n",
      "792/792 [==============================] - 0s 579us/step - loss: -746.1686 - mean_absolute_error: 45.3470 - val_loss: -354.1947 - val_mean_absolute_error: 20.5589\n",
      "Epoch 41/50\n",
      "792/792 [==============================] - 0s 600us/step - loss: -743.0132 - mean_absolute_error: 45.3165 - val_loss: -354.1947 - val_mean_absolute_error: 20.5191\n",
      "Epoch 42/50\n",
      "792/792 [==============================] - 0s 566us/step - loss: -750.6820 - mean_absolute_error: 45.2424 - val_loss: -354.1947 - val_mean_absolute_error: 20.4938\n",
      "Epoch 43/50\n",
      "792/792 [==============================] - 0s 566us/step - loss: -749.4775 - mean_absolute_error: 45.2242 - val_loss: -354.1947 - val_mean_absolute_error: 20.4459\n",
      "Epoch 44/50\n",
      "792/792 [==============================] - 0s 601us/step - loss: -750.1054 - mean_absolute_error: 45.2071 - val_loss: -354.1947 - val_mean_absolute_error: 20.4455\n",
      "Epoch 45/50\n",
      "792/792 [==============================] - 0s 602us/step - loss: -749.1172 - mean_absolute_error: 45.2320 - val_loss: -354.1947 - val_mean_absolute_error: 20.4446\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "792/792 [==============================] - 0s 530us/step - loss: -751.2849 - mean_absolute_error: 45.1930 - val_loss: -354.1947 - val_mean_absolute_error: 20.4446\n",
      "Epoch 47/50\n",
      "792/792 [==============================] - 0s 533us/step - loss: -751.3502 - mean_absolute_error: 45.1976 - val_loss: -354.1947 - val_mean_absolute_error: 20.4599\n",
      "Epoch 48/50\n",
      "792/792 [==============================] - 0s 493us/step - loss: -750.2236 - mean_absolute_error: 45.2210 - val_loss: -354.1947 - val_mean_absolute_error: 20.4691\n",
      "Epoch 49/50\n",
      "792/792 [==============================] - 0s 543us/step - loss: -750.4371 - mean_absolute_error: 45.2468 - val_loss: -354.1947 - val_mean_absolute_error: 20.4705\n",
      "Epoch 50/50\n",
      "792/792 [==============================] - 0s 533us/step - loss: -751.1626 - mean_absolute_error: 45.2253 - val_loss: -354.1947 - val_mean_absolute_error: 20.4658\n",
      "990/990 [==============================] - 0s 37us/step\n",
      "mean_absolute_error: 4027.8533161047735\n"
     ]
    }
   ],
   "source": [
    "model = trainLSTM(dataX,dataY,3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveModel(model, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = readModel(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of Predictable Data: 107\n",
      "Predictable Data: [[135 135  61]\n",
      " [135 135  61]]\n"
     ]
    }
   ],
   "source": [
    "predictableData = getPredictableData(datetime.datetime(2018, 1, 27, 14, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "print(predictableData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.9607518]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(predictableData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 48., 125.,   0.],\n",
       "       [ 48., 125.,   0.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 48.  48.]\n",
      "  [125. 125.]\n",
      "  [  0.   0.]]]\n",
      "[[ 48.  48.]\n",
      " [125. 125.]\n",
      " [  0.   0.]]\n",
      "[48. 48.]\n",
      "48.0\n"
     ]
    }
   ],
   "source": [
    "tmp = np.asarray(dataX[0:1])\n",
    "# tmp = np.reshape(tmp, (len(tmp),3,2))\n",
    "tmp = np.swapaxes(tmp,1,2)\n",
    "print(tmp)\n",
    "print(tmp[0])\n",
    "print(tmp[0][0])\n",
    "print(tmp[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 48. 125.   0.]\n",
      "  [ 48. 125.   0.]]]\n"
     ]
    }
   ],
   "source": [
    "tmp = np.asarray(dataX[0:1])\n",
    "tmp[0].transpose()\n",
    "# tmp = np.reshape(tmp, (len(tmp),3,2))\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected lstm_1_input to have shape (3, 2) but got array with shape (2, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-cc2be794acb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1025\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m         return self.model.predict(x, batch_size=batch_size, verbose=verbose,\n\u001b[0;32m-> 1027\u001b[0;31m                                   steps=steps)\n\u001b[0m\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1780\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1781\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1782\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1783\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1784\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    118\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected lstm_1_input to have shape (3, 2) but got array with shape (2, 3)"
     ]
    }
   ],
   "source": [
    "model.predict(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
