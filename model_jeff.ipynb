{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yao-chiehhu/anaconda3/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "import time\n",
    "import pickle\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.pickle', 'rb') as handle:\n",
    "    fullHeadTailDataList = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare two datasets: Enrol+Quota+Wait and Wait-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullHeadTailDataListEQW = []\n",
    "for item in fullHeadTailDataList:\n",
    "    fullHeadTailDataListEQW.append([item['enrol'],item['quota'],item['wait']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullHeadTailDataListWAIT = []\n",
    "for item in fullHeadTailDataList:\n",
    "    fullHeadTailDataListWAIT.append(item['wait'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictableData(_datetime):\n",
    "    index = -1\n",
    "    # Capture datetime\n",
    "    for ind,row in enumerate(fullHeadTailDataList):\n",
    "        if (row['datetime'] == _datetime):\n",
    "            index = ind\n",
    "            \n",
    "    print(\"Index of Predictable Data:\", index)\n",
    "    \n",
    "    \n",
    "    # Found corresponding datetime\n",
    "    if (index != -1):\n",
    "        res = fullHeadTailDataListEQW[index-1:index+1]\n",
    "        print(\"Predictable Data:\", res)\n",
    "        return np.asarray(res).reshape(1,3,2)\n",
    "    else:\n",
    "        return np.zeros(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create lookback "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back=1): \n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset)-look_back):\n",
    "        a = dataset[i:i+look_back]\n",
    "        X.append(a)\n",
    "        Y.append(dataset[i + look_back]) \n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel(model, modelFilenamePrefix):\n",
    "    structureFilename = modelFilenamePrefix + \".json\" \n",
    "    model_json = model.to_json()\n",
    "    with open(structureFilename, \"w\") as f:\n",
    "        f.write(model_json)\n",
    "        \n",
    "    weightFilename = modelFilenamePrefix + \".h5\" \n",
    "    model.save_weights(weightFilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readModel(modelFilenamePrefix):\n",
    "    structureFilename = modelFilenamePrefix + \".json\" \n",
    "    with open(structureFilename, \"r\") as f:\n",
    "        model_json = f.read()\n",
    "    model = model_from_json(model_json)\n",
    "\n",
    "    weightFilename = modelFilenamePrefix + \".h5\" \n",
    "    model.load_weights(weightFilename)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,dataY = create_dataset(fullHeadTailDataListWAIT, 2)\n",
    "dataX,_ = create_dataset(fullHeadTailDataListEQW, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(990, 2, 3)\n",
      "(990,)\n"
     ]
    }
   ],
   "source": [
    "print(dataX.shape)\n",
    "print(dataY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainData(X,Y,_dim):\n",
    "    X = np.asarray(X)\n",
    "    Y = np.asarray(Y)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=_dim, activation='relu')) \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"mae\"])\n",
    "    model.fit(X, Y, epochs=50, batch_size=4, validation_split=0.2)\n",
    "\n",
    "    scores = model.evaluate(X, Y)\n",
    "    print(\"{}: {}\".format(model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,dataY = create_dataset(fullHeadTailDataListWAIT, 2)\n",
    "dataX,_ = create_dataset(fullHeadTailDataListEQW, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,dataY = create_dataset(fullHeadTailDataListWAIT, 2)\n",
    "dataX,_ = create_dataset(fullHeadTailDataListEQW, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainLSTM(X,Y, dim=1, lookback=1):\n",
    "    # Reshape to fit the LSTM model\n",
    "    X = np.reshape(X, (len(X),dim,lookback))\n",
    "        \n",
    "    # Model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(4, input_shape=(dim,lookback)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"mae\"])\n",
    "    model.fit(X, Y, epochs=50, batch_size=8, validation_split=0.2)\n",
    "\n",
    "    # Ealuation\n",
    "    scores = model.evaluate(X, Y)\n",
    "    print(\"{}: {}\".format(model.metrics_names[1], scores[1]*100))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 48.  48.  60. ... 138. 138. 138.]\n",
      " [  0.   0.   0. ...  17.  17.  17.]\n",
      " [125. 125. 125. ... 140. 140. 140.]]\n",
      "Train on 792 samples, validate on 198 samples\n",
      "Epoch 1/50\n",
      "792/792 [==============================] - 1s 2ms/step - loss: 106.0927 - mean_absolute_error: 48.0022 - val_loss: 36.3626 - val_mean_absolute_error: 23.0432\n",
      "Epoch 2/50\n",
      "792/792 [==============================] - 0s 511us/step - loss: 72.6696 - mean_absolute_error: 47.9169 - val_loss: 24.6362 - val_mean_absolute_error: 22.9576\n",
      "Epoch 3/50\n",
      "792/792 [==============================] - 0s 532us/step - loss: 45.6397 - mean_absolute_error: 47.8223 - val_loss: 15.4707 - val_mean_absolute_error: 22.8738\n",
      "Epoch 4/50\n",
      "792/792 [==============================] - 0s 505us/step - loss: 28.7395 - mean_absolute_error: 47.7430 - val_loss: 7.2451 - val_mean_absolute_error: 22.7887\n",
      "Epoch 5/50\n",
      "792/792 [==============================] - 0s 491us/step - loss: 10.6382 - mean_absolute_error: 47.6626 - val_loss: -1.0911 - val_mean_absolute_error: 22.6975\n",
      "Epoch 6/50\n",
      "792/792 [==============================] - 0s 511us/step - loss: -11.3751 - mean_absolute_error: 47.5603 - val_loss: -10.9911 - val_mean_absolute_error: 22.5910\n",
      "Epoch 7/50\n",
      "792/792 [==============================] - 0s 555us/step - loss: -49.8613 - mean_absolute_error: 47.4269 - val_loss: -29.1961 - val_mean_absolute_error: 22.4272\n",
      "Epoch 8/50\n",
      "792/792 [==============================] - 0s 561us/step - loss: -531.5313 - mean_absolute_error: 47.2618 - val_loss: -47.7746 - val_mean_absolute_error: 22.3210\n",
      "Epoch 9/50\n",
      "792/792 [==============================] - 0s 513us/step - loss: -609.9629 - mean_absolute_error: 47.2233 - val_loss: -49.2644 - val_mean_absolute_error: 22.3150\n",
      "Epoch 10/50\n",
      "792/792 [==============================] - 0s 517us/step - loss: -563.9130 - mean_absolute_error: 47.2594 - val_loss: -51.4727 - val_mean_absolute_error: 22.3066\n",
      "Epoch 11/50\n",
      "792/792 [==============================] - 0s 520us/step - loss: -594.6639 - mean_absolute_error: 47.2212 - val_loss: -53.6075 - val_mean_absolute_error: 22.2991\n",
      "Epoch 12/50\n",
      "792/792 [==============================] - 0s 520us/step - loss: -592.2444 - mean_absolute_error: 47.2173 - val_loss: -56.0534 - val_mean_absolute_error: 22.2912\n",
      "Epoch 13/50\n",
      "792/792 [==============================] - 0s 515us/step - loss: -606.1040 - mean_absolute_error: 47.1994 - val_loss: -58.8132 - val_mean_absolute_error: 22.2831\n",
      "Epoch 14/50\n",
      "792/792 [==============================] - 0s 559us/step - loss: -606.4915 - mean_absolute_error: 47.1943 - val_loss: -61.7911 - val_mean_absolute_error: 22.2754\n",
      "Epoch 15/50\n",
      "792/792 [==============================] - 0s 572us/step - loss: -577.5973 - mean_absolute_error: 47.2159 - val_loss: -66.0563 - val_mean_absolute_error: 22.2657\n",
      "Epoch 16/50\n",
      "792/792 [==============================] - 0s 535us/step - loss: -587.5882 - mean_absolute_error: 47.1862 - val_loss: -71.6469 - val_mean_absolute_error: 22.2553\n",
      "Epoch 17/50\n",
      "792/792 [==============================] - 0s 543us/step - loss: -580.7945 - mean_absolute_error: 47.1902 - val_loss: -79.2146 - val_mean_absolute_error: 22.2446\n",
      "Epoch 18/50\n",
      "792/792 [==============================] - 0s 528us/step - loss: -594.9450 - mean_absolute_error: 47.1668 - val_loss: -89.9745 - val_mean_absolute_error: 22.2343\n",
      "Epoch 19/50\n",
      "792/792 [==============================] - 1s 635us/step - loss: -579.5953 - mean_absolute_error: 47.1636 - val_loss: -116.2954 - val_mean_absolute_error: 22.2225\n",
      "Epoch 20/50\n",
      "792/792 [==============================] - 0s 583us/step - loss: -591.1388 - mean_absolute_error: 47.1479 - val_loss: -354.1947 - val_mean_absolute_error: 22.2114\n",
      "Epoch 21/50\n",
      "792/792 [==============================] - 0s 584us/step - loss: -596.7197 - mean_absolute_error: 47.1307 - val_loss: -354.1947 - val_mean_absolute_error: 22.2000\n",
      "Epoch 22/50\n",
      "792/792 [==============================] - 0s 591us/step - loss: -606.1256 - mean_absolute_error: 47.1130 - val_loss: -354.1947 - val_mean_absolute_error: 22.1885\n",
      "Epoch 23/50\n",
      "792/792 [==============================] - 0s 522us/step - loss: -580.9397 - mean_absolute_error: 47.1246 - val_loss: -354.1947 - val_mean_absolute_error: 22.1751\n",
      "Epoch 24/50\n",
      "792/792 [==============================] - 0s 527us/step - loss: -593.8452 - mean_absolute_error: 47.0990 - val_loss: -354.1947 - val_mean_absolute_error: 22.1620\n",
      "Epoch 25/50\n",
      "792/792 [==============================] - 0s 539us/step - loss: -577.0092 - mean_absolute_error: 47.1048 - val_loss: -354.1947 - val_mean_absolute_error: 22.1468\n",
      "Epoch 26/50\n",
      "792/792 [==============================] - 0s 553us/step - loss: -608.3404 - mean_absolute_error: 47.0613 - val_loss: -354.1947 - val_mean_absolute_error: 22.1336\n",
      "Epoch 27/50\n",
      "792/792 [==============================] - 0s 538us/step - loss: -591.0931 - mean_absolute_error: 47.0644 - val_loss: -354.1947 - val_mean_absolute_error: 22.1181\n",
      "Epoch 28/50\n",
      "792/792 [==============================] - 0s 558us/step - loss: -604.4815 - mean_absolute_error: 47.0312 - val_loss: -354.1947 - val_mean_absolute_error: 22.1032\n",
      "Epoch 29/50\n",
      "792/792 [==============================] - 0s 538us/step - loss: -612.3918 - mean_absolute_error: 47.0149 - val_loss: -354.1947 - val_mean_absolute_error: 22.0889\n",
      "Epoch 30/50\n",
      "792/792 [==============================] - 0s 531us/step - loss: -599.4349 - mean_absolute_error: 47.0127 - val_loss: -354.1947 - val_mean_absolute_error: 22.0727\n",
      "Epoch 31/50\n",
      "792/792 [==============================] - 0s 525us/step - loss: -596.4261 - mean_absolute_error: 46.9995 - val_loss: -354.1947 - val_mean_absolute_error: 22.0552\n",
      "Epoch 32/50\n",
      "792/792 [==============================] - 0s 531us/step - loss: -598.6493 - mean_absolute_error: 46.9832 - val_loss: -354.1947 - val_mean_absolute_error: 22.0371\n",
      "Epoch 33/50\n",
      "792/792 [==============================] - 0s 584us/step - loss: -591.1795 - mean_absolute_error: 46.9639 - val_loss: -354.1947 - val_mean_absolute_error: 22.0166\n",
      "Epoch 34/50\n",
      "792/792 [==============================] - 0s 594us/step - loss: -612.4836 - mean_absolute_error: 46.9259 - val_loss: -354.1947 - val_mean_absolute_error: 21.9970\n",
      "Epoch 35/50\n",
      "792/792 [==============================] - 0s 609us/step - loss: -582.8963 - mean_absolute_error: 46.9439 - val_loss: -354.1947 - val_mean_absolute_error: 21.9740\n",
      "Epoch 36/50\n",
      "792/792 [==============================] - 0s 568us/step - loss: -599.8605 - mean_absolute_error: 46.9028 - val_loss: -354.1947 - val_mean_absolute_error: 21.9504\n",
      "Epoch 37/50\n",
      "792/792 [==============================] - 0s 533us/step - loss: -605.7339 - mean_absolute_error: 46.8738 - val_loss: -354.1947 - val_mean_absolute_error: 21.9264\n",
      "Epoch 38/50\n",
      "792/792 [==============================] - 0s 590us/step - loss: -608.8773 - mean_absolute_error: 46.8459 - val_loss: -354.1947 - val_mean_absolute_error: 21.9016\n",
      "Epoch 39/50\n",
      "792/792 [==============================] - 0s 526us/step - loss: -598.6228 - mean_absolute_error: 46.8382 - val_loss: -354.1947 - val_mean_absolute_error: 21.8731\n",
      "Epoch 40/50\n",
      "792/792 [==============================] - 0s 570us/step - loss: -602.9544 - mean_absolute_error: 46.8013 - val_loss: -354.1947 - val_mean_absolute_error: 21.8416\n",
      "Epoch 41/50\n",
      "792/792 [==============================] - 0s 570us/step - loss: -602.8289 - mean_absolute_error: 46.7715 - val_loss: -354.1947 - val_mean_absolute_error: 21.8069\n",
      "Epoch 42/50\n",
      "792/792 [==============================] - 0s 528us/step - loss: -601.0053 - mean_absolute_error: 46.7323 - val_loss: -354.1947 - val_mean_absolute_error: 21.7675\n",
      "Epoch 43/50\n",
      "792/792 [==============================] - 0s 542us/step - loss: -604.0367 - mean_absolute_error: 46.6909 - val_loss: -354.1947 - val_mean_absolute_error: 21.7216\n",
      "Epoch 44/50\n",
      "792/792 [==============================] - 0s 605us/step - loss: -613.1873 - mean_absolute_error: 46.6330 - val_loss: -354.1947 - val_mean_absolute_error: 21.6633\n",
      "Epoch 45/50\n",
      "792/792 [==============================] - 0s 536us/step - loss: -617.6730 - mean_absolute_error: 46.5647 - val_loss: -354.1947 - val_mean_absolute_error: 21.5561\n",
      "Epoch 46/50\n",
      "792/792 [==============================] - 0s 519us/step - loss: -742.7140 - mean_absolute_error: 46.4297 - val_loss: -354.1947 - val_mean_absolute_error: 21.4942\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "792/792 [==============================] - 0s 531us/step - loss: -751.2849 - mean_absolute_error: 46.4129 - val_loss: -354.1947 - val_mean_absolute_error: 21.4942\n",
      "Epoch 48/50\n",
      "792/792 [==============================] - 0s 577us/step - loss: -751.2849 - mean_absolute_error: 46.4474 - val_loss: -354.1947 - val_mean_absolute_error: 21.4942\n",
      "Epoch 49/50\n",
      "792/792 [==============================] - 0s 568us/step - loss: -751.2849 - mean_absolute_error: 46.4269 - val_loss: -354.1947 - val_mean_absolute_error: 21.4942\n",
      "Epoch 50/50\n",
      "792/792 [==============================] - 0s 537us/step - loss: -751.2849 - mean_absolute_error: 46.4248 - val_loss: -354.1947 - val_mean_absolute_error: 21.4942\n",
      "990/990 [==============================] - 0s 35us/step\n",
      "mean_absolute_error: 4144.82908730555\n"
     ]
    }
   ],
   "source": [
    "model = trainLSTM(dataX,dataY,3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveModel(model, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = readModel(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictNewDatasetFromModel(newInputAttributeDataFilename, newTargetAttributeDataFilename, model):\n",
    "#     newX = numpy.loadtxt(newInputAttributeDataFilename, delimiter=\",\")\n",
    "    newY = model.predict(newX, batch_size=10)\n",
    "    numpy.savetxt(newTargetAttributeDataFilename, newY, delimiter=\",\", fmt=\"%.10f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of Predictable Data: 107\n",
      "Predictable Data: [[135, 135, 61], [135, 135, 61]]\n"
     ]
    }
   ],
   "source": [
    "predictableData = getPredictableData(datetime.datetime(2018, 1, 27, 14, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[135 135]\n",
      "  [ 61 135]\n",
      "  [135  61]]]\n"
     ]
    }
   ],
   "source": [
    "predictableData\n",
    "print(predictableData)\n",
    "predictableData = np.reshape(predictableData, (len(predictableData),3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.7229867]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(predictableData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 48., 125.,   0.],\n",
       "       [ 48., 125.,   0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 48. 125.   0.]\n",
      "  [ 48. 125.   0.]]]\n"
     ]
    }
   ],
   "source": [
    "tmp = np.asarray(dataX[0:1])\n",
    "# tmp = np.reshape(tmp, (len(tmp),3,2))\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 48. 125.   0.]\n",
      "  [ 48. 125.   0.]]]\n"
     ]
    }
   ],
   "source": [
    "tmp = np.asarray(dataX[0:1])\n",
    "tmp[0].transpose()\n",
    "# tmp = np.reshape(tmp, (len(tmp),3,2))\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected lstm_1_input to have shape (3, 2) but got array with shape (2, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-cc2be794acb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1025\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m         return self.model.predict(x, batch_size=batch_size, verbose=verbose,\n\u001b[0;32m-> 1027\u001b[0;31m                                   steps=steps)\n\u001b[0m\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1780\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1781\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1782\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1783\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1784\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    118\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected lstm_1_input to have shape (3, 2) but got array with shape (2, 3)"
     ]
    }
   ],
   "source": [
    "model.predict(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
